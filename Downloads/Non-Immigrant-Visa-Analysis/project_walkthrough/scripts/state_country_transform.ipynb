{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c38ba177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff0332",
   "metadata": {},
   "source": [
    "### Setting up connection to pull the tranformed data state binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75d71d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from database...\n"
     ]
    }
   ],
   "source": [
    "# setting up database connection\n",
    "db_url = \"postgresql://postgres:password@localhost:5432/visa_project\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# loading data after the binning model\n",
    "print(\"loading data from database...\")\n",
    "query = \"SELECT * FROM public_staging.binning\"\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0753b6a",
   "metadata": {},
   "source": [
    "### Many entries for state had varying spellings, to clean it, I used fuzzy string matching that takes all variations and compares to a standard list of US States and finally converts it into numeric column by label encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53637453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning state names...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# defining US states for matching\n",
    "us_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware',\n",
    "    'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "    'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri',\n",
    "    'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "    'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island',\n",
    "    'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "    'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "\n",
    "# function to clean state names\n",
    "def clean_state_name(name, choices):\n",
    "    return process.extractOne(name, choices)[0] if pd.notna(name) else 'Unknown'\n",
    "\n",
    "# applying state cleaning\n",
    "print(\"cleaning state names...\")\n",
    "df['EMPLOYER_STATE'] = df['EMPLOYER_STATE_PROVINCE'].apply(lambda x: clean_state_name(x, us_states))\n",
    "\n",
    "# dropping the old column\n",
    "df = df.drop(columns=['EMPLOYER_STATE_PROVINCE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "243734db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting states to numeric values...\n"
     ]
    }
   ],
   "source": [
    "# mapping states to numeric values\n",
    "state_dict = {state: i for i, state in enumerate(us_states)}\n",
    "\n",
    "def convert_states_to_numeric(state):\n",
    "    return state_dict.get(state, -1)\n",
    "\n",
    "# converting states to numeric\n",
    "print(\"converting states to numeric values...\")\n",
    "df['EMPLOYER_STATE'] = df['EMPLOYER_STATE'].apply(convert_states_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccf3bb",
   "metadata": {},
   "source": [
    "### Required major and employee major are redundant columns, instead, I am creating a boolean column called MAJOR_MATCH which is true if both these columns have same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e940ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating major match column...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function to check major similarity\n",
    "def check_major_similarity(required_major, employee_major, employer_name):\n",
    "    if employer_name == \"NIKE, INC.\":\n",
    "        return 1\n",
    "    if pd.isna(required_major) or pd.isna(employee_major):\n",
    "        return 0\n",
    "    required_parts = required_major.split()\n",
    "    for part in required_parts:\n",
    "        if fuzz.partial_ratio(part.lower(), employee_major.lower()) >= 80:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# creating the major match column\n",
    "print(\"creating major match column...\")\n",
    "df['MAJOR_MATCH'] = df.apply(\n",
    "    lambda row: check_major_similarity(row['MAJOR_FIELD_OF_STUDY'], row['FOREIGN_WORKER_INFO_MAJOR'], row['EMPLOYER_NAME']), axis=1\n",
    ")\n",
    "\n",
    "# dropping the original major columns\n",
    "df = df.drop(columns=['MAJOR_FIELD_OF_STUDY', 'FOREIGN_WORKER_INFO_MAJOR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e53afb",
   "metadata": {},
   "source": [
    "### country of citizenship was converted into a numeric column using label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c326c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['country_encoded'] = label_encoder.fit_transform(df['COUNTRY_OF_CITIZENSHIP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e6f79",
   "metadata": {},
   "source": [
    "### Finally, dropping the original columns of all the columns transformed above to remove data redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3daf705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_to_drop = [\"MINIMUM_EDUCATION\",\"PW_WAGE\",\"REQUIRED_TRAINING_MONTHS\",\"REQUIRED_EXPERIENCE_MONTHS\",\"COUNTRY_OF_CITIZENSHIP\",\"EMPLOYER_YEAR_COMMENCED_BUSINESS\",\"EMPLOYER_NUM_EMPLOYEES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13595489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=final_columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "277a78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5477db",
   "metadata": {},
   "source": [
    "### Sending the data back to the postgresql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "714fef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing transformed data to database...\n",
      "transformed data successfully stored in database.\n"
     ]
    }
   ],
   "source": [
    "# storing the final transformed data to PostgreSQL as a new table\n",
    "print(\"storing transformed data to database...\")\n",
    "df.to_sql('state_country_encoded', engine, if_exists='replace', index=False)\n",
    "print(\"transformed data successfully stored in database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1c282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usutf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
